<!DOCTYPE html>
<html>
<head>
    <title>A-Frame WebXR Gesture Recognition</title>
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet@2.2.2/dist/posenet.min.js"></script>
    
    <style>
        body { margin: 0; overflow: hidden; }
        /* Canvas สำหรับ Debug จะถูกสร้างโดย component และวางทับบนหน้าจอ */
    </style>

    <script>
        // --- ส่วนที่ 1: A-Frame Component สำหรับจัดการกล้องและ ML ---
        AFRAME.registerComponent('gesture-detector', {
            schema: {
                modelType: {type: 'string', default: 'posenet'},
                debug: {type: 'boolean', default: false} 
            },
            init: function () {
                console.log("Gesture Detector: Initializing...");
                this.videoEl = null;
                this.model = null;
                this.lastPose = null;
                this.isDetecting = false;

                this.canvas = document.createElement('canvas');
                this.canvasContext = this.canvas.getContext('2d');
                if (this.data.debug) {
                    this.canvas.style.position = 'fixed';
                    this.canvas.style.top = '0';
                    this.canvas.style.left = '0';
                    this.canvas.style.zIndex = '9999';
                    document.body.appendChild(this.canvas);
                }

                this.el.sceneEl.addEventListener('enter-vr', this.onEnterVR.bind(this));
                this.el.sceneEl.addEventListener('exit-vr', this.onExitVR.bind(this));
            },

            //... (ฟังก์ชัน onEnterVR, onExitVR, loadModel, detectPoseInVideo ยังคงเหมือนเดิม) ...
            
            // --- ฟังก์ชัน onEnterVR (คัดลอกมาเหมือนเดิม) ---
            onEnterVR: async function () {
                console.log("Entered VR/AR. Attempting to access camera...");
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: {facingMode: "environment"} }); // ใช้กล้องหลังสำหรับ AR
                    this.videoEl = document.createElement('video');
                    this.videoEl.srcObject = stream;
                    this.videoEl.autoplay = true;
                    this.videoEl.playsInline = true;
                    this.videoEl.style.display = 'none';
                    document.body.appendChild(this.videoEl);

                    this.videoEl.onloadedmetadata = () => {
                        this.videoEl.play();
                        this.canvas.width = this.videoEl.videoWidth;
                        this.canvas.height = this.videoEl.videoHeight;
                        this.loadModel();
                    };

                } catch (err) {
                    console.error("Error accessing camera:", err);
                    alert("ไม่สามารถเข้าถึงกล้องได้ ตรวจสอบสิทธิ์การเข้าถึงกล้องของคุณ");
                }
            },
            
            // --- ฟังก์ชัน onExitVR (คัดลอกมาเหมือนเดิม) ---
            onExitVR: function () {
                console.log("Exited VR/AR. Stopping camera stream...");
                if (this.videoEl && this.videoEl.srcObject) {
                    this.videoEl.srcObject.getTracks().forEach(track => track.stop());
                    this.videoEl.remove();
                    this.videoEl = null;
                }
                this.model = null;
                this.isDetecting = false;
            },

            // --- ฟังก์ชัน loadModel (คัดลอกมาเหมือนเดิม) ---
            loadModel: async function () {
                console.log(`Loading ${this.data.modelType} model...`);
                this.isDetecting = true;
                try {
                    if (this.data.modelType === 'posenet') {
                        this.model = await posenet.load({
                            architecture: 'MobileNetV1',
                            outputStride: 16,
                            inputResolution: { width: 640, height: 480 },
                            multiplier: 0.75
                        });
                        console.log("PoseNet model loaded.");
                    } 
                    this.detectPoseInVideo();
                } catch (error) {
                    console.error("Failed to load ML model:", error);
                    this.isDetecting = false;
                }
            },

            // --- ฟังก์ชัน detectPoseInVideo (คัดลอกมาเหมือนเดิม) ---
            detectPoseInVideo: async function () {
                if (!this.isDetecting || !this.model || !this.videoEl || this.videoEl.readyState !== 4) {
                    requestAnimationFrame(this.detectPoseInVideo.bind(this));
                    return;
                }

                if (this.data.modelType === 'posenet') {
                    const pose = await this.model.estimateSinglePose(this.videoEl, {
                        flipHorizontal: false,
                        decodingMethod: 'single-person'
                    });
                    this.processPose(pose);
                } 

                requestAnimationFrame(this.detectPoseInVideo.bind(this));
            },

            processPose: function (pose) {
                if (!pose || !pose.keypoints) return;
                this.lastPose = pose;

                if (this.data.debug) {
                    this.canvasContext.clearRect(0, 0, this.canvas.width, this.canvas.height);
                    this.canvasContext.drawImage(this.videoEl, 0, 0, this.canvas.width, this.canvas.height);
                    drawKeypoints(pose.keypoints, this.canvasContext);
                    drawSkeleton(pose.keypoints, this.canvasContext);
                }

                // 2. ตรรกะการตรวจจับท่าทาง (Gesture Recognition Logic)
                const parts = (part) => pose.keypoints.find(kp => kp.part === part);

                const leftShoulder = parts('leftShoulder');
                const leftElbow = parts('leftElbow');
                const leftWrist = parts('leftWrist');
                const nose = parts('nose');
                
                // ตรวจสอบความแม่นยำขั้นต่ำ
                const minScore = 0.7;
                
                // ตรวจจับท่าทาง: ยกมือซ้ายขึ้นเหนือไหล่
                if (leftShoulder && leftWrist && leftWrist.score > minScore && leftShoulder.score > minScore) {
                    if (leftWrist.position.y < leftShoulder.position.y - 50) { 
                        this.el.sceneEl.emit('leftHandUp'); 
                        return; // ตรวจพบท่าทางหลัก, หยุดตรวจจับท่าทางอื่น
                    }
                }
                
                // ตรวจจับท่าทาง: กางแขนซ้ายออกไปด้านข้าง (Stretched Out)
                if (leftShoulder && leftElbow && leftWrist && leftElbow.score > minScore) {
                    // ถ้าข้อมือซ้ายอยู่ไกลจากไหล่ซ้ายในแนวนอน และอยู่ต่ำกว่าไหล่เล็กน้อย
                    const isStretched = leftWrist.position.x < leftShoulder.position.x - 100; // ห่างกันมากกว่า 100px ในแนวนอน
                    const isLevel = Math.abs(leftWrist.position.y - leftShoulder.position.y) < 50; // อยู่ในระดับเดียวกัน (บวกลบ 50px)

                    if (isStretched && isLevel) {
                         this.el.sceneEl.emit('leftArmStretched');
                         return; // ตรวจพบท่าทางหลัก, หยุดตรวจจับท่าทางอื่น
                    }
                }
                
                // หากไม่พบท่าทางใด ๆ
                this.el.sceneEl.emit('noGesture');
                this.el.sceneEl.emit('pose-update', { pose: pose });
            }
        });
        
        // --- ส่วนที่ 2: ฟังก์ชัน Helper สำหรับวาด Debug (จาก TensorFlow.js PoseNet) ---
        // ฟังก์ชันเหล่านี้จำเป็นสำหรับการวาดโครงกระดูกเมื่อ debug: true
        const color = 'aqua';
        const lineWidth = 2;
        const minConfidence = 0.5;

        function toTuple({y, x}) { return [y, x]; }

        function drawSegment([ay, ax], [by, bx], color, scale, ctx) {
            ctx.beginPath();
            ctx.moveTo(ax * scale, ay * scale);
            ctx.lineTo(bx * scale, by * scale);
            ctx.lineWidth = lineWidth;
            ctx.strokeStyle = color;
            ctx.stroke();
        }

        function drawKeypoints(keypoints, ctx) {
            for (let i = 0; i < keypoints.length; i++) {
                const keypoint = keypoints[i];
                if (keypoint.score < minConfidence) continue;
                const {y, x} = keypoint.position;
                ctx.beginPath();
                ctx.arc(x, y, 3, 0, 2 * Math.PI);
                ctx.fillStyle = color;
                ctx.fill();
            }
        }
        
        // 
        
        function drawSkeleton(keypoints, ctx, scale = 1) {
            // ใช้ posenet.getAdjacentKeyPoints เพื่อดึงคู่จุดเชื่อมต่อ
            const adjacentKeyPoints = posenet.getAdjacentKeyPoints(keypoints, minConfidence);
            
            adjacentKeyPoints.forEach((keypoints) => {
                drawSegment(toTuple(keypoints[0].position),
                            toTuple(keypoints[1].position), color, scale, ctx);
            });
        }
    </script>
</head>
<body>
    <a-scene xr-mode-ui="enabled: true" gesture-detector="debug: true; modelType: posenet">
        
        <a-entity camera look-controls position="0 1.6 0"></a-entity>
        
        <a-box id="responseBox" position="0 1 -3" rotation="0 45 0" color="#4CC3D9"></a-box>

        <a-entity id="debugText" text="value: No gesture detected; width: 2" position="0 2.5 -2.5"></a-entity>

        <a-plane position="0 0 -4" rotation="-90 0 0" width="10" height="10" color="#7BC8A4"></a-plane>
        <a-sky color="#ECECEC"></a-sky>

        <a-light type="ambient" color="#BBB"></a-light>
        <a-light type="directional" intensity="0.5" position="1 1 1"></a-light>
    </a-scene>

    <script>
        // --- Logic สำหรับตอบสนองต่อเหตุการณ์ใน Scene ---
        const sceneEl = document.querySelector('a-scene');
        const box = document.querySelector('#responseBox');
        const text = document.querySelector('#debugText');
        
        let resetColorTimeout = null;
        
        const resetState = () => {
             box.setAttribute('color', '#4CC3D9');
             text.setAttribute('text', 'value: No gesture detected');
        }

        // ท่าทาง: ยกมือซ้ายขึ้น
        sceneEl.addEventListener('leftHandUp', function () {
            console.log("Scene: Left hand is up!");
            box.setAttribute('color', 'red'); 
            text.setAttribute('text', 'value: Left Hand Up! (Red Box)');
            
            clearTimeout(resetColorTimeout);
            resetColorTimeout = setTimeout(resetState, 2000);
        });

        // ท่าทาง: กางแขนซ้าย
        sceneEl.addEventListener('leftArmStretched', function () {
            console.log("Scene: Left arm stretched!");
            box.setAttribute('color', 'yellow'); // เปลี่ยนเป็นสีเหลือง
            text.setAttribute('text', 'value: Left Arm Stretched! (Yellow Box)');
            
            clearTimeout(resetColorTimeout);
            resetColorTimeout = setTimeout(resetState, 2000);
        });

        // ท่าทาง: ไม่มี
        sceneEl.addEventListener('noGesture', function() {
            // หากไม่ตรวจพบท่าทางหลักใดๆ ระบบจะรอให้ timeout หมดไปก่อนค่อย reset
            // หากตรวจพบท่าทาง ระบบจะ clear timeout เก่าและตั้ง timeout ใหม่
        });

    </script>
</body>
</html>